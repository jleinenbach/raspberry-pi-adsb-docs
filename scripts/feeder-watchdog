#!/bin/bash
set -o pipefail
#===============================================================================
# Feeder Watchdog - Mit exponentiellem Backoff und Telegram-Benachrichtigungen
# Versuche: 5min ‚Üí 10min ‚Üí 20min ‚Üí 40min ‚Üí 80min ‚Üí 160min ‚Üí aufgeben
# Gesamtzeit bis Eskalation: ~5 Stunden
#
# v2.1 - 2026-01-29: OGN-RF Health Check mit Port 8080 Abfrage
#===============================================================================

DEPENDENCIES="NetworkManager chronyd dbus systemd-udevd"
FEEDERS="readsb piaware fr24feed adsbexchange-feed adsbfi-feed opensky-feeder theairtraffic-feed rbfeeder airplanes-feed pfclient adsbexchange-mlat adsbfi-mlat airplanes-mlat tar1090 graphs1090 adsbexchange-stats ogn-rf-procserv ogn-decode-procserv ogn2dump1090 dragonsync aircraft-alert-notifier ogn-balloon-notifier drone-alert-notifier"
LOG="/var/log/feeder-watchdog.log"
FAIL_DIR="/var/run/feeder-watchdog"
MAX_FAILURES=6
BASE_INTERVAL=300  # 5 Minuten in Sekunden
PROBLEMS=0

# Telegram-Konfiguration
TELEGRAM_CONF="/etc/telegram-notify.conf"
NOTIFY_ENABLED=true

mkdir -p "$FAIL_DIR"
#-------------------------------------------------------------------------------
# Sichere Telegram-Config Ladung (ohne source)
#-------------------------------------------------------------------------------
load_telegram_config() {
    local conf="${1:-/etc/telegram-notify.conf}"
    [ ! -f "$conf" ] && return 1
    TELEGRAM_BOT_TOKEN=$(grep "^TELEGRAM_BOT_TOKEN=" "$conf" 2>/dev/null | cut -d= -f2- | tr -d '"' )
    TELEGRAM_CHAT_ID=$(grep "^TELEGRAM_CHAT_ID=" "$conf" 2>/dev/null | cut -d= -f2- | tr -d '"' )
    [ -z "$TELEGRAM_BOT_TOKEN" ] || [ -z "$TELEGRAM_CHAT_ID" ] && return 1
    return 0
}

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> "$LOG"
}

#-------------------------------------------------------------------------------
# Telegram-Benachrichtigung
#-------------------------------------------------------------------------------
notify() {
    local type="$1"
    local message="$2"

    [ "$NOTIFY_ENABLED" != "true" ] && return
    [ ! -f "$TELEGRAM_CONF" ] && return

    load_telegram_config "$TELEGRAM_CONF" || return
    [ -z "$TELEGRAM_BOT_TOKEN" ] || [ -z "$TELEGRAM_CHAT_ID" ] && return

    local emoji=""
    case "$type" in
        ok)       emoji="‚úÖ" ;;
        warning)  emoji="‚ö†Ô∏è" ;;
        error)    emoji="üî¥" ;;
        info)     emoji="‚ÑπÔ∏è" ;;
    esac

    curl -s --max-time 10 -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" \
        -d chat_id="${TELEGRAM_CHAT_ID}" \
        -d text="${emoji} *Watchdog*: ${message}" \
        -d parse_mode="Markdown" > /dev/null 2>&1
}

#-------------------------------------------------------------------------------
# OGN-RF Health Check - unterscheidet Benchmarking von echten Fehlern
#-------------------------------------------------------------------------------
check_ogn_rf_health() {
    # Ist der Service laut systemd active?
    if ! systemctl is-active ogn-rf-procserv &>/dev/null; then
        echo "service_down"
        return 1
    fi
    
    # Ist Port 8080 erreichbar?
    if curl -s --max-time 2 http://localhost:8080/status.html > /dev/null 2>&1; then
        echo "healthy"
        return 0
    fi
    
    # Port nicht erreichbar - pr√ºfe ob procServ l√§uft und CPU-Last
    if pgrep -f "procServ.*50000.*ogn-rf" &>/dev/null; then
        # Pr√ºfe CPU-Last des ogn-rf Prozesses
        local cpu=$(ps aux | grep "[.]./ogn-rf SteGau.conf" | awk '{print int($3)}')
        if [ "$cpu" -gt 50 ]; then
            # Hohe CPU-Last = wahrscheinlich FFTW Benchmarking
            echo "benchmarking"
            return 2
        else
            # Niedriger CPU, aber Port nicht offen = Problem
            echo "unhealthy"
            return 1
        fi
    else
        echo "crashed"
        return 1
    fi
}

#-------------------------------------------------------------------------------
# Failure-Tracking mit Zeitstempel f√ºr exponentiellen Backoff
#-------------------------------------------------------------------------------
get_failure_count() {
    local svc="$1"
    local file="$FAIL_DIR/$svc.failures"
    [ -f "$file" ] && head -1 "$file" || echo 0
}

get_last_attempt() {
    local svc="$1"
    local file="$FAIL_DIR/$svc.failures"
    [ -f "$file" ] && tail -1 "$file" || echo 0
}

get_wait_time() {
    local failures="$1"
    echo $((BASE_INTERVAL * (2 ** failures)))
}

record_failure() {
    local svc="$1"
    local count=$(get_failure_count "$svc")
    local new_count=$((count + 1))
    local now=$(date +%s)
    echo -e "$new_count\n$now" > "$FAIL_DIR/$svc.failures"
    echo $new_count
}

reset_failures() {
    local svc="$1"
    rm -f "$FAIL_DIR/$svc.failures" "$FAIL_DIR/$svc.given_up"
}

is_given_up() {
    local svc="$1"
    [ -f "$FAIL_DIR/$svc.given_up" ]
}

should_try_now() {
    local svc="$1"
    local failures=$(get_failure_count "$svc")
    local last_attempt=$(get_last_attempt "$svc")
    local now=$(date +%s)
    local wait_time=$(get_wait_time "$failures")
    local elapsed=$((now - last_attempt))
    [ "$elapsed" -ge "$wait_time" ]
}

format_duration() {
    local seconds="$1"
    if [ "$seconds" -ge 3600 ]; then
        echo "$((seconds / 3600))h $((seconds % 3600 / 60))min"
    else
        echo "$((seconds / 60))min"
    fi
}

#-------------------------------------------------------------------------------
# Service-Reparatur mit exponentiellem Backoff
#-------------------------------------------------------------------------------
try_repair_service() {
    local svc="$1"
    local type="$2"

    # Spezialbehandlung f√ºr ogn-rf-procserv
    if [ "$svc" = "ogn-rf-procserv" ]; then
        local health=$(check_ogn_rf_health)
        
        if [ "$health" = "healthy" ]; then
            if [ -f "$FAIL_DIR/$svc.failures" ]; then
                log "OK: $svc l√§uft wieder - Fehlerz√§hler zur√ºckgesetzt"
                notify "ok" "$svc l√§uft wieder (Benchmarking abgeschlossen)"
                reset_failures "$svc"
            fi
            return 0
        elif [ "$health" = "benchmarking" ]; then
            # Benchmarking - nicht als Fehler behandeln, aber loggen
            if [ ! -f "$FAIL_DIR/$svc.benchmarking" ]; then
                log "INFO: $svc l√§uft FFTW Benchmarking (10-15 Min, CPU ~90%)"
                touch "$FAIL_DIR/$svc.benchmarking"
            fi
            return 0
        else
            # Echtes Problem - normale Reparatur
            rm -f "$FAIL_DIR/$svc.benchmarking"
            # Fall through zu normaler Behandlung
        fi
    fi

    STATUS=$(systemctl is-active "$svc" 2>/dev/null)

    if [ "$STATUS" = "active" ]; then
        if [ -f "$FAIL_DIR/$svc.failures" ]; then
            log "OK: $svc l√§uft wieder - Fehlerz√§hler zur√ºckgesetzt"
            notify "ok" "$svc l√§uft wieder"
            reset_failures "$svc"
        fi
        return 0
    fi

    # "activating" ist normaler √úbergangszustand beim Start - nicht eingreifen!
    if [ "$STATUS" = "activating" ]; then
        # Nur beim ersten Mal loggen (kein Spam)
        if [ ! -f "$FAIL_DIR/$svc.activating_seen" ]; then
            log "INFO: $svc ist activating - warte auf selbst√§ndige Aktivierung"
            touch "$FAIL_DIR/$svc.activating_seen"
        fi
        return 0
    else
        # Wenn nicht mehr activating, l√∂sche Marker
        rm -f "$FAIL_DIR/$svc.activating_seen"
    fi

    if is_given_up "$svc"; then
        return 1
    fi

    local failures=$(get_failure_count "$svc")

    if [ "$failures" -ge "$MAX_FAILURES" ]; then
        if [ ! -f "$FAIL_DIR/$svc.given_up" ]; then
            log "ESKALATION: $svc nach $MAX_FAILURES Versuchen (~5h) aufgegeben ‚Üí Claude-Wartung"
            notify "error" "$svc nach 5h Versuchen aufgegeben. Warte auf Claude-Wartung um 07:00."
            touch "$FAIL_DIR/$svc.given_up"
        fi
        PROBLEMS=$((PROBLEMS + 1))
        return 1
    fi

    if ! should_try_now "$svc"; then
        return 1
    fi

    local next_wait=$(format_duration $(get_wait_time $((failures + 1))))
    log "VERSUCH: $svc ist $STATUS (Versuch $((failures + 1))/$MAX_FAILURES, n√§chster in $next_wait)"

    if [ "$failures" -eq 0 ]; then
        notify "warning" "$svc ist $STATUS - starte Reparatur"
    fi

    systemctl restart "$svc" 2>/dev/null
    sleep 3

    NEW_STATUS=$(systemctl is-active "$svc" 2>/dev/null)
    if [ "$NEW_STATUS" = "active" ]; then
        log "OK: $svc erfolgreich neugestartet"
        notify "ok" "$svc erfolgreich neugestartet"
        reset_failures "$svc"
        return 0
    else
        local new_failures=$(record_failure "$svc")
        log "FEHLER: $svc ist jetzt $NEW_STATUS (Fehlschlag $new_failures/$MAX_FAILURES)"
        if [ "$new_failures" -eq "$MAX_FAILURES" ]; then
            log "ESKALATION: $svc nach $MAX_FAILURES Versuchen (~5h) aufgegeben ‚Üí Claude-Wartung"
            notify "error" "$svc nach 5h Versuchen aufgegeben. Warte auf Claude-Wartung um 07:00."
            touch "$FAIL_DIR/$svc.given_up"
        fi
        PROBLEMS=$((PROBLEMS + 1))
        return 1
    fi
}

#-------------------------------------------------------------------------------
# Netzwerk-Check
#-------------------------------------------------------------------------------
check_network() {
    if ping -c 1 -W 5 8.8.8.8 &>/dev/null; then
        if [ -f "$FAIL_DIR/network.failures" ]; then
            log "OK: Netzwerk wiederhergestellt"
            notify "ok" "Netzwerk wiederhergestellt"
        fi
        reset_failures "network"
        return 0
    fi

    if is_given_up "network"; then
        return 1
    fi

    local failures=$(get_failure_count "network")

    if [ "$failures" -ge "$MAX_FAILURES" ]; then
        if [ ! -f "$FAIL_DIR/network.given_up" ]; then
            log "ESKALATION: Netzwerk nach $MAX_FAILURES Versuchen (~5h) aufgegeben"
            notify "error" "Netzwerk seit 5h offline - Eskalation an Claude"
            touch "$FAIL_DIR/network.given_up"
        fi
        return 1
    fi

    if ! should_try_now "network"; then
        return 1
    fi

    local next_wait=$(format_duration $(get_wait_time $((failures + 1))))
    log "NETZWERK: Keine Verbindung (Versuch $((failures + 1))/$MAX_FAILURES, n√§chster in $next_wait)"

    if [ "$failures" -eq 0 ]; then
        notify "warning" "Netzwerk offline - versuche Reparatur"
    fi

    record_failure "network"
    return 1
}

#-------------------------------------------------------------------------------
# AtomS3 Check (nur wenn Device existiert)
#-------------------------------------------------------------------------------
check_atoms3() {
    if [ ! -e "/dev/remoteid" ]; then
        reset_failures "zmq-decoder"
        return 0
    fi

    if systemctl is-active zmq-decoder &>/dev/null; then
        if [ -f "$FAIL_DIR/zmq-decoder.failures" ]; then
            log "OK: zmq-decoder l√§uft wieder"
            reset_failures "zmq-decoder"
        fi
        return 0
    fi

    try_repair_service "zmq-decoder" "optional"
}

#-------------------------------------------------------------------------------
# Main Loop
#-------------------------------------------------------------------------------
check_network

for dep in $DEPENDENCIES; do
    try_repair_service "$dep" "critical"
done

for feeder in $FEEDERS; do
    try_repair_service "$feeder" "feeder"
done

check_atoms3

# Log-Rotation (max 1000 Zeilen)
if [ $(wc -l < "$LOG" 2>/dev/null || echo 0) -gt 1000 ]; then
    tail -500 "$LOG" > "$LOG.tmp" && chmod 644 "$LOG.tmp" && mv "$LOG.tmp" "$LOG"
fi

exit $PROBLEMS
