# System Changelog

**System:** Raspberry Pi 4 Model B - ADS-B/OGN/Remote ID Feeder
**Letzte Aktualisierung:** 2026-02-08

Chronologische Historie aller implementierten System-√Ñnderungen.

## 2026-02-08 - KRITISCH: PENDING-Session Bug - User-Antworten wurden ignoriert

### Problem: 2 Stunden Totenstille nach User-Antwort

**Symptome:**
- User antwortete innerhalb 24h-Frist auf readsb-Update-Frage
- Bot best√§tigte: "‚úÖ Antwort erhalten, wird validiert..."
- **Dann passierte 2 Stunden NICHTS!**
- /var/log lief auf 70% voll (Kollateralschaden)
- User erhielt erst dann Alarm

**Root Cause:** Fundamentaler Design-Bug im PENDING-Session-Workflow:

```
1. Wartung erstellt PENDING-Session (state="waiting_for_answer")
2. User antwortet via Telegram Bot
3. Bot schreibt Antwort nach /run/telegram-bot-answer
4. Bot sendet "wird validiert..." und startet claude-respond.service
5. ‚ùå claude-respond-to-reports LIEST /run/telegram-bot-answer NICHT!
6. ‚ùå Session bleibt in state="waiting_for_answer"
7. ‚ùå Wartung beendet sich: "Session wartet noch - √ºberspringe Wartung"
8. ‚ùå Kein Code validiert Antwort oder resumed Session!
```

**Zus√§tzlicher Bug:**
- Selbst wenn Antwort gelesen worden w√§re: `exit 0` nach Sekret√§r-Validierung verhinderte Wartungs-Fortsetzung!

### L√∂sung: Komplette PENDING-Answer-Logik implementiert

**Datei:** `/usr/local/sbin/claude-respond-to-reports`

**1. User-Antwort-Handler (Zeile 242+):**
```bash
elif [ "$SESSION_STATE" = "waiting_for_answer" ]; then
    # Pr√ºfe ob User via Telegram geantwortet hat
    ANSWER_FILE="/run/telegram-bot-answer"
    if [ -f "$ANSWER_FILE" ]; then
        USER_ANSWER=$(cat "$ANSWER_FILE")
        rm -f "$ANSWER_FILE"

        # Sekret√§r validieren
        VALIDATION=$(/usr/local/sbin/telegram-secretary "$PENDING_QUESTION" "$USER_ANSWER")

        # Session updaten mit validierter Antwort
        jq '.state = "answered" | .interactions += [...]' "$SESSION_FILE"

        # PENDING_ANSWER setzen f√ºr Wartungs-Fortsetzung
        PENDING_ANSWER="$VALIDATION"

        # User-Feedback via Telegram
        case "$PENDING_ANSWER" in
            GENEHMIGT:*) telegram-notify "‚úÖ Anfrage genehmigt...";;
            ABGELEHNT:*) telegram-notify "üõ°Ô∏è Anfrage abgelehnt...";;
        esac
    fi
fi
```

**2. Problematisches `exit 0` entfernt (Zeile 304):**
```bash
# VOR dem Fix:
            fi
            exit 0  # ‚Üê VERHINDERTE Wartungs-Fortsetzung!
        fi

# NACH dem Fix:
            fi
        fi  # exit 0 entfernt ‚Üí Wartung l√§uft weiter
```

### Workflow VORHER vs. NACHHER

**‚ùå Vorher:**
```
07:15 - Wartung erstellt PENDING-Session
07:15 - Wartung beendet sich (Exit 1)
09:00 - User antwortet "Ja, Update durchf√ºhren"
09:00 - Bot: "wird validiert..."
09:00 - Bot startet claude-respond.service
09:00 - claude-respond: "Session wartet noch" ‚Üí Exit 0
[... 2 Stunden Totenstille ...]
11:00 - /var/log 70% voll ‚Üí Alarm
```

**‚úÖ Nachher:**
```
07:15 - Wartung erstellt PENDING-Session
07:15 - Wartung beendet sich (Exit 1, korrekt)
09:00 - User antwortet "Ja, Update durchf√ºhren"
09:00 - Bot: "wird validiert..."
09:00 - Bot startet claude-respond.service
09:00 - claude-respond liest /run/telegram-bot-answer
09:00 - Sekret√§r validiert: "GENEHMIGT: System-Update durchf√ºhren"
09:00 - Session State ‚Üí "answered"
09:01 - Wartung setzt fort mit User-Genehmigung
09:01 - Techniker-Claude f√ºhrt readsb-Update durch
```

### Betroffene Komponenten

| Komponente | √Ñnderung |
|------------|----------|
| `/usr/local/sbin/claude-respond-to-reports` | **+60 Zeilen** User-Antwort-Handler |
| `/usr/local/sbin/claude-respond-to-reports` | **-1 Zeile** Problematisches `exit 0` |
| `/run/telegram-bot-answer` | Jetzt gelesen & gel√∂scht |
| `/var/lib/claude-pending/session.json` | State: waiting ‚Üí answered |

### Kollateralschaden: /var/log 70% voll

**W√§hrend der 2h Totenstille liefen Logs voll:**
- chrony/tracking.log.1: 1.2M (von gestern, nicht rotiert)
- rbfeeder.log: 768K (keine Rotation konfiguriert)
- Alte *.log.1 Dateien: ~1M

**Sofortma√ünahmen:**
```bash
# Alte Logs l√∂schen
sudo rm /var/log/*.log.1 /var/log/*.log.*.gz
sudo rm /var/log/chrony/tracking.log.1

# rbfeeder Log truncaten
sudo truncate -s 0 /var/log/rbfeeder.log

# rbfeeder Logrotate konfigurieren
cat > /etc/logrotate.d/rbfeeder <<'LOGROTATE'
/var/log/rbfeeder.log {
    daily
    rotate 1
    maxsize 200K
    compress
}
LOGROTATE
```

**Ergebnis:** 70% ‚Üí 64%

### Test & Verifikation

**Test 1: User-Antwort-Erkennung**
```bash
# Simuliere User-Antwort
echo "Ja, Update durchf√ºhren" | sudo tee /run/telegram-bot-answer

# Starte Wartung
sudo systemctl start claude-respond.service

# Verifikation in Logs:
[2026-02-08 11:28:13] User-Antwort via Telegram gefunden: Ja, Update durchf√ºhren
[2026-02-08 11:28:32] Sekret√§r-Validierung: GENEHMIGT: System-Update durchf√ºhren
```
‚úÖ **Erfolgreich!**

**Test 2: Wartungs-Fortsetzung**
```bash
# Pr√ºfe Session State
jq '.state' /var/lib/claude-pending/session.json
# Output: "answered"

# Pr√ºfe ob Claude CLI l√§uft (Wartung aktiv)
pgrep -f "claude -p"
# Output: 2453434 (Techniker-Claude l√§uft!)
```
‚úÖ **Erfolgreich!**

### Backup & Rollback

**Backups:**
- `/usr/local/sbin/claude-respond-to-reports.backup-before-pending-fix`
- `/usr/local/sbin/claude-respond-to-reports.backup2`

**Rollback:**
```bash
sudo cp /usr/local/sbin/claude-respond-to-reports.backup-before-pending-fix \
        /usr/local/sbin/claude-respond-to-reports
sudo systemctl restart claude-respond.service
```

### Lessons Learned

**1. PENDING-Sessions m√ºssen vollst√§ndigen Lifecycle haben:**
- ‚úÖ Erstellen (claude -p mit telegram-ask)
- ‚úÖ User-Antwort empfangen (telegram-bot ‚Üí /run/telegram-bot-answer)
- ‚úÖ **NEU:** Antwort lesen & validieren (Sekret√§r)
- ‚úÖ **NEU:** Session State updaten (waiting ‚Üí answered)
- ‚úÖ **NEU:** Wartung fortsetzen (ohne exit 0)

**2. Totenstille ist inakzeptabel:**
- User muss **sofort** Feedback bekommen wenn etwas h√§ngt
- Nicht erst nach 2 Stunden wenn Kollateralsch√§den auftreten!

**3. tmpfs /var/log braucht Logrotate:**
- Verbose Services (rbfeeder) m√ºssen rotiert werden
- Alte .log.1 Dateien m√ºssen automatisch gel√∂scht werden

### Status

‚úÖ **Produktiv seit 2026-02-08 11:28**
- PENDING-Sessions funktionieren jetzt vollst√§ndig
- User-Antworten werden sofort verarbeitet
- Wartung setzt nach Genehmigung automatisch fort
- Keine Totenstille mehr!

---

## 2026-02-07 - Feeder-Watchdog: Robuster Netzwerk-Check

### Problem
Der Netzwerk-Check in `/usr/local/sbin/feeder-watchdog` war zu strikt und verursachte **False Positives**:
- Nur ein einzelner Ping zu 8.8.8.8
- Ein verlorenes Paket = "Netzwerk offline"
- Telegram-Warnung schon beim **ersten Fehler**

**Paradox:** Watchdog sendete Telegram-Nachricht √ºber das "offline"-Netzwerk.

### Root Cause
Einzelner Ping zu einzelnem Host ist nicht robust genug:
- Paket-Verlust (1-2%) ist normal
- DNS-Server kann tempor√§r √ºberlastet sein
- Routing-Probleme zu einem Host ‚â† komplett offline

### L√∂sung
Multi-Host Multi-Ping Check:

```bash
check_network() {
    local hosts=(
        "8.8.8.8"      # Google DNS (Internet)
        "1.1.1.1"      # Cloudflare DNS (Internet)
        "192.168.1.1"  # Gateway (LAN)
    )

    # 2 Pings pro Host, 3s Timeout
    for host in "${hosts[@]}"; do
        if ping -c 2 -W 3 "$host" &>/dev/null; then
            # Mindestens ein Host erreichbar = OK
            return 0
        fi
    done

    # ALLE Hosts fehlgeschlagen = offline
    # Warnung erst ab 2. Fehler (toleriert einzelne Ausrutscher)
}
```

**Verbesserungen:**
1. **Multi-Host:** 3 verschiedene Ziele (Internet + LAN)
2. **Multi-Ping:** 2 Pings pro Host (reduziert Paket-Verlust-Effekt)
3. **Fail-Safe:** Nur wenn ALLE Hosts fehlschlagen = offline
4. **Toleranz:** Warnung erst ab 2. konsekutivem Fehler

### Test
```bash
# Vor der √Ñnderung:
Teste 8.8.8.8: ‚úó nicht erreichbar (1 Ping verloren)
‚Üí Netzwerk offline (False Positive!)

# Nach der √Ñnderung:
Teste 8.8.8.8: ‚úì erreichbar (2 von 2 Pings)
‚Üí Netzwerk OK (bricht ab, testet 1.1.1.1 nicht mehr)
```

### Dateien
- `/usr/local/sbin/feeder-watchdog` - `check_network()` Zeile 305-357
- Backup: `/usr/local/sbin/feeder-watchdog.backup-before-network-fix`

---

## 2026-02-06 - Wartungs-Watchdog: Fix False-Positive bei PENDING-Sessions

### Problem
Der Wartungs-Watchdog (`/usr/local/sbin/wartungs-watchdog`) behandelte **alle Exit-Codes != 0** als Fehler, aber Claude CLI gibt **Exit 1 zur√ºck wenn eine PENDING-Session erstellt wird** (User-R√ºckfrage ohne sofortige Antwort).

**Symptom:**
- Claude-Wartung stellt User-Frage via `telegram-ask`
- User antwortet nicht innerhalb 2 Minuten ‚Üí PENDING-Session erstellt
- Claude beendet sich korrekt mit "[TELEGRAM:OK] Wartung pausiert..."
- **Aber**: Claude CLI gibt Exit 1 zur√ºck (technisch korrekt f√ºr "nicht vollst√§ndig abgeschlossen")
- Watchdog erkennt "Exit 1" im Log und startet Diagnose-Claude
- Telegram-Alarm: "Wartung reagiert nicht mehr - Diagnose fehlgeschlagen (Exit 1)"

**Root Cause:**
PENDING-Sessions sind ein **normaler Zustand** (Wartung pausiert auf User-Antwort), aber Watchdog behandelte sie als Fehler.

### L√∂sung
`check_recent_errors()` in wartungs-watchdog erweitert:
```bash
# WICHTIG: Exit 1 mit PENDING-Session ist KEIN Fehler!
# Claude pausiert auf User-Antwort ‚Üí normaler Zustand
local session_file="/var/lib/claude-pending/session.json"
if [ -f "$session_file" ]; then
    local session_state=$(jq -r ".state" "$session_file" 2>/dev/null)
    if [ "$session_state" = "waiting_for_answer" ]; then
        log "INFO: Exit 1 mit PENDING-Session (waiting_for_answer) ‚Üí OK, kein Fehler"
        return 1  # Kein Fehler - Wartung pausiert auf User
    fi
fi
```

**Verhalten jetzt:**
- Exit 1 **MIT** PENDING-Session ‚Üí OK, keine Diagnose
- Exit 1 **OHNE** PENDING-Session ‚Üí Fehler, Diagnose startet

### Ge√§ndert
- `/usr/local/sbin/wartungs-watchdog`: PENDING-Session-Handling in `check_recent_errors()`

### Dokumentiert
- LESSONS-LEARNED.md: Entry geplant f√ºr Wartungs-Watchdog False-Positives

**Test-Fall (2026-02-06):**
- Session 1770358592: SSH-H√§rtung Frage (noch aktiv, l√§uft bis 2026-02-07 07:16)
- Exit 1 wurde korrekt als PENDING erkannt ‚Üí Keine Fehlalarm mehr


---

## 2026-02-06 - zmq-decoder Architecture Analysis & New Governance Rules

### Analysiert
- **zmq-decoder Entfernung (retrospektiv)**:
  - Problem: Service war nie aktiv (inactive seit 02.02, disabled)
  - Ursache: PORT-KONFLIKT mit atoms3-proxy (beide Port 4224)
  - Service-Config war fehlerhaft: `--zmqsetting localhost:4224` ohne `--zmqclients`
  - zmq-decoder h√§tte subscriben sollen, aber versuchte zu publizieren
  - Watchdog-Eskalation am 03.02 nach 6 Versuchen (~5h)
  - Wartung entfernte Service am 06.02 ohne Analyse/User-R√ºckfrage

### Entfernt
- **zmq-decoder.service**: Redundant und fehlkonfiguriert
  - Problem: Port-Konflikt mit atoms3-proxy
  - Alternative: atoms3-proxy hat alle ben√∂tigten Features
  - ESP32-Firmware dekodiert bereits OpenDroneID ‚Üí zmq-decoder unn√∂tig
  - Multi-Source/DJI/externe ZMQ-Clients nicht ben√∂tigt

### Behalten
- **atoms3-proxy**: Einziger Serial Reader f√ºr AtomS3
  - Einfaches Routing: remoteid ‚Üí Port 4224, probe ‚Üí Port 4225
  - Production-Features: Backoff, Logging, Signal Handling
  - L√§uft stabil seit 04.02 (2+ Tage)

### Neu: Governance Rules f√ºr Architekturentscheidungen
- **CLAUDE.md**: Neue Sektion "üèóÔ∏è Architekturentscheidungen"
  - 5-Level Eskalations-Leiter (Restart ‚Üí Repair ‚Üí Watchdog ‚Üí Deep Dive ‚Üí Architecture)
  - Pflicht: Deep Dive Analyse BEVOR Komponenten entfernt werden
  - Pflicht: User-R√ºckfrage via Telegram mit vollst√§ndiger Erkl√§rung
  - Pflicht: Rollback-F√§higkeit (Service auf `.disabled`, nie l√∂schen!)
  - Pflicht: Dokumentation (CHANGELOG + CLAUDE.md + Rollback-Skript)
  - Verboten: Services l√∂schen, Configs l√∂schen, Datenfluss ohne Analyse √§ndern

### Dokumentiert
- **DRAGONSYNC.md**: Architektur-Diagramm korrigiert (zmq-decoder entfernt)
- **CLAUDE.md**: atoms3-proxy bleibt single Serial Reader
- **LESSONS-LEARNED.md**: ZMQ Patterns, Port-Konflikte, Service-Validierung


---


## 2026-02-05 - MQTT Discovery Fix & Telegram /stats Erweiterung

### Behoben
- **Home Assistant MQTT Discovery Error**:
  - Problem: NTRIP Server als `sensor` mit `device_class: 'connectivity'` publiziert
  - Fehler: `'expected SensorDeviceClass or one of...' for dictionary value @ data['device_class']`
  - Ursache: `connectivity` ist nur f√ºr `binary_sensor` g√ºltig, nicht f√ºr `sensor`
  - Fix: `/usr/local/sbin/gps-mqtt-publisher` refactored
    - `sensors[]` Array getrennt von `binary_sensors[]` Array
    - NTRIP Server nach `binary_sensors` verschoben
    - Discovery Topic ge√§ndert: `sensor/...` ‚Üí `binary_sensor/.../config`
    - Alte retained MQTT message manuell gel√∂scht
  - Resultat: Entity jetzt korrekt als `binary_sensor.ntrip_server` in HA
  - Dokumentiert in: `~/docs/GPS-HOME-ASSISTANT.md` (Troubleshooting)

### Ge√§ndert
- **Telegram Bot `/stats` Erweiterung**:
  - OGN-Statistiken erweitert: `/min, /Stunde` ‚Üí `/min, /h, /12h`
  - 12h-Wert wird direkt von ogn-decode Status-Seite gelesen (keine Sch√§tzung)
  - Format: `ü™Ç Empfangen: 0/min, 0/h, 0/12h`
  - Datei: `/usr/local/sbin/telegram-bot-daemon`

### Dokumentiert
- **Apt-Pinning False Positive**:
  - Problem: Wartung alarmierte "System teilweise auf trixie migriert"
  - Tats√§chlich: Bewusstes Pinning f√ºr `ca-certificates` aus trixie
  - Ursache: Wartungslogik pr√ºfte nur `/etc/apt/sources.list`, nicht Pinning-Config
  - L√∂sung: Dokumentation in `~/docs/CLAUDE.md` erweitert
    - Neue Sektion: "Apt-Pinning: bookworm + trixie Mix (BEABSICHTIGT!)"
    - Priorit√§ten erkl√§rt: bookworm=900, trixie=50, ca-certificates=990
    - Diagnose-Befehle hinzugef√ºgt
  - Lesson Learned in `~/docs/LESSONS-LEARNED.md` erg√§nzt
    - Neue Sektion: "Apt & Package Management (2026-02-05)"
    - Trixie-Quellen ‚â† Migration wenn Pinning konfiguriert ist

---

## 2026-02-04 - Telegram Bot: /gps Befehl und HTML Migration

### Hinzugef√ºgt
- **`/gps` Befehl**: Zeigt umfassenden GPS/RTK Status
  - Hardware-Info (Waveshare LC29H, PPS Pin)
  - GPS Fix Qualit√§t und Position (RTK Fixed)
  - PPS Zeitgenauigkeit (Stratum, Offset, Samples)
  - Satelliten-Sch√§tzung und Signalqualit√§t
  - Almanach/Ephemeris Status
  - NTRIP Base Station Status (Clients, Uptime)
  - Service-Status (ntripcaster, ntrip-proxy, chronyd, gps-mqtt)
  - Software-Versionen (RTKLIB, chrony, gpsd)

### Ge√§ndert
- **Telegram Bot Migration zu HTML**:
  - Alle Bot-Befehle von Markdown V2 auf HTML umgestellt
  - `parse_mode="HTML"` statt Markdown
  - `escape_html()` Funktion (escaped nur `&`, `<`, `>`)
  - `*Text*` ‚Üí `<b>Text</b>` in allen Funktionen
  - Escaped Pipes `\|` entfernt (nicht n√∂tig in HTML)
  - Viel einfacher als MarkdownV2 (18 vs 3 Special Characters)

### Behoben
- **Telegram HTML `&` Zeichen Problem**:
  - Telegram HTML erlaubt KEIN `&` innerhalb von `<b>` Tags
  - "Almanach & Ephemeris" ‚Üí "Almanach und Ephemeris"
  - Verursachte "Can't find end tag corresponding to start tag 'b'" Fehler
  - `&amp;` Escaping funktioniert auch nicht innerhalb von Bold-Tags

### Entfernt
- GNSS-Systeme Abschnitt aus `/gps` (statische Info ohne Mehrwert)

---

## Implemented Changes (Gruppiert)

### Security & Hardening (2026-01-16 bis 2026-01-31)
- SSH hardening, Protocols disabled, Core dumps off, UMASK 027
- Kernel Security Hardening (`/etc/sysctl.d/99-security.conf`)
- AppArmor f√ºr: readsb, piaware, rbfeeder, pfclient, airplanes-feed
- Systemd Hardening: autogain1090 (9.6‚Üí4.6), readsb (9.2‚Üí6.7)
- Security Tools: debsecan, lynis, aide, rkhunter, apt-listbugs
- apt-listbugs: Blockiert unattended-upgrades bei kritischen Bugs
- STRG-1846: Firewire-Module geblacklistet (`/etc/modprobe.d/blacklist-firewire.conf`)
- HRDN-7222: Compiler (gcc/g++) nur f√ºr root zug√§nglich
- PKGS-7370: debsums w√∂chentliche Integrit√§tspr√ºfung aktiviert
- Script Security Audit: 'set -o pipefail' f√ºr alle Skripte (2026-02-02)

### ADS-B Services (18 Services nach Kategorie)
- **Core:** readsb
- **Upload Feeds (9):** piaware, fr24feed, adsbexchange-feed, adsbfi-feed, opensky-feeder, theairtraffic-feed, rbfeeder, airplanes-feed, pfclient
- **MLAT (4):** mlathub, adsbexchange-mlat, adsbfi-mlat, airplanes-mlat
- **Web (3):** tar1090, graphs1090, adsbexchange-stats

### DragonSync - Drohnen-Erkennung (2026-01-27)
**‚ùå KEIN √∂ffentliches Upload m√∂glich** - Remote-ID-Daten bleiben lokal (Datenschutz/Rechtslage)

**Warum kein Upload?**
- EU DSGVO & USA Privacy Laws verbieten unbefugte Weitergabe
- Kein Community-Netzwerk vorhanden (im Gegensatz zu ADS-B/OGN)
- Remote ID ist f√ºr lokale Beh√∂rden, nicht f√ºr √∂ffentliches Tracking
- Kommerzielle Alternativen nur f√ºr Beh√∂rden (DroneScout, Dronetag Cloud)

**Setup:**
- DragonSync Gateway (`dragonsync.service`)
- atoms3-proxy - Single Serial Reader (`atoms3-proxy.service`)
- MQTT ‚Üí Home Assistant Discovery
- udev-Regel f√ºr AtomS3 (`/dev/remoteid`)
- FAA RID Lookup-Datenbank
- **Datenfluss:** AtomS3 (BLE) ‚Üí atoms3-proxy ‚Üí DragonSync ‚Üí Home Assistant (nur MQTT, lokal)

### Monitoring & Automation
- feeder-watchdog (5min) mit Telegram + exponential backoff
- wartungs-watchdog (10min) f√ºr Claude-Wartung
- Claude auto-maint (07:00), daily-summary (06:55)
- SD-Health-Check, config-backup (w√∂chentlich)
- wiedehopf Update-Check in Wartung integriert
- RPi Firmware-Update-Check in /status und Wartung (2026-01-22)
- /do Queue-System f√ºr Telegram-Befehle (2026-01-23)
- Fix: daily-summary z√§hlt nur Reparaturen der letzten 24h (2026-01-25)
- Fix: /status SD-Fehler nur 24h statt seit Boot (2026-01-25)
- Fix: Sekret√§r-Validierung robuster, Fallback-Genehmigung (2026-01-25)
- Lynis-Vorschl√§ge im Wartungsskript gleichwertig behandelt (2026-01-25)
- CVE pip-Patcher: Automatische Python-Paket-Updates bei Wartung (2026-01-25)
- Script Security Audit: W√∂chentliche Pr√ºfung eigener Skripte (2026-01-25)
- npm/claude-code Update-Check: W√∂chentlich Sonntag 05:50 (2026-01-26)
- ADSBexchange Binary-Update-Check: feed-adsbx + mlat-client (2026-01-26)
- adsb.fi Binary-Update-Check: feed-adsbfi + mlat-client (2026-01-26)
- SDR-Frozen-Detection im Watchdog: Erkennt eingefrorenen RTL-SDR (2026-01-26)
- Fix: log-persist-restore Boot-Zyklus behoben (2026-01-26)
- Fix: Service-Z√§hlung konsistent auf 18‚Üí19‚Üí20‚Üí21 Services (daily-summary, claude-respond-to-reports) (2026-01-29)
- **OGN/FLARM vollst√§ndig aktiviert:** Station "SteGau" online mit procServ-√ºberwachtem ogn-rf/ogn-decode (2026-01-29)
  - ogn-rf-procserv (v0.2.6) - RF-Empfang auf Port 8080
  - ogn-decode-procserv (v0.3.2) - APRS-Upload auf Port 8081
  - TCP-Kommunikation √ºber localhost:50010 funktioniert
  - ogn2dump1090 empf√§ngt zus√§tzlich APRS-Stream (100km-Radius)
- **Watchdog OGN Health Check:** Port 8080-Abfrage, erkennt Benchmarking (hohe CPU), keine False-Positives (2026-01-29)
- **Telegram /status OGN-Statistiken:** Zeigt "Aircrafts received/min" von Port 8081 (2026-01-29)
- **Vollst√§ndige 3-Luftverkehrs-Statistiken:** ADS-B + OGN + Drohnen in allen Monitoring-Tools (2026-01-30)
  - `/status`: Drohnen-Anzahl live ("DragonSync - Drohnen: X aktiv")
  - `/stats`: Erweitert um OGN (Empfang/min, /Stunde) + Drohnen (aktuell, 24h)
  - `daily-summary`: ADS-B tracks + OGN (12h) + Drohnen (24h)
  - Komplette √úbersicht: ‚úàÔ∏è Verkehrsflugzeuge, ü™Ç Segelflugzeuge, üöÅ Drohnen
  - **Layout-Reorganisation:** OGN/FLARM von Hardware ‚Üí Services, Firmware in Hardware integriert
  - **Konsistentes Format:** Ampel-Icons VOR Labels (z.B. "üü¢ Firmware: Aktuell" statt "Firmware: üü¢ Aktuell")
  - **Entfernt:** TheAirTraffic "Extern"-Sektion (redundant, bereits in Upload Feeds gez√§hlt)
  - **Bug-Fix:** Einsame "0" nach Drohnen-Stats (wc -l + || echo "0" gab doppelte Ausgabe)
- **Telegram Bot Lock-Mechanismen (2026-01-30):**
  - **Bot-Instance-Lock:** PID-File verhindert mehrere Bot-Instanzen (`/var/run/telegram-bot.pid`)
  - **Command-Lock:** Pro-Befehl Lock verhindert Doppel-Verarbeitung von /status, /stats, /log, /wartung (3 Sekunden)
  - **Array-basierte Update-Verarbeitung:** Ersetzt pipe-while (Subshell-Problem) durch mapfile+for (Haupt-Shell)
  - **Problem gel√∂st:** Mehrfach-Ausgaben bei schnellen wiederholten Befehlen
- **FFTW Wisdom:** `/etc/fftw/wisdomf` generiert (460B, NEON-optimiert), aber ogn-rf nutzt es nicht (kein import/export_wisdom im Code, Test best√§tigt) (2026-01-29)
- **RTL-SDR Treiber-Validierung:** V4-spezifischer R828D-Tuner korrekt erkannt, keine generischen Fallback-Treiber (2026-01-29)
- **Spannungs√ºberwachung:** USB-Spannungspr√ºfung (`vcgencmd get_throttled`) in /status, Wartung und daily-summary integriert - Erkennt Netzteil-Probleme (0x0=OK, 0x50000=Warnung, 0x50005=Kritisch) (2026-01-29)
  - Telegram Bot zeigt in `/status`: "üü¢ Spannung: Stabil"
  - Daily Summary (06:55): Zeigt Spannungsstatus vor Wartung
  - Wartungsskript: "=== STROMVERSORGUNG ===" Sektion
  - Vollst√§ndig getestet und dokumentiert ‚Üí `docs/VOLTAGE-MONITORING.md`
- **tmpfs /var/log Schutz (2026-01-31):**
  - Aggressive Log-Rotation f√ºr syslog/kern.log (5M, alle 30min)
  - Verhindert tmpfs-Volllauf bei USB-Fehler-Flut (`/etc/logrotate.d/rsyslog-tmpfs`)
  - Cron-basierte Rotation (`/etc/cron.d/tmpfs-logrotate`)
- **tmpfs Boot-Persistence f√ºr Custom Log-Verzeichnisse (2026-02-02):**
  - Problem: `/var/log/rtl-ogn/` wurde bei jedem Boot gel√∂scht (tmpfs = fl√ºchtig)
  - Symptom: OGN-Services crashten mit Status 209/STDOUT (kann Log-Datei nicht √∂ffnen)
  - Root Cause: Nur Dateien in `log-persist.conf`, keine Verzeichnis-Struktur
  - Fix: systemd-tmpfiles.d-Regel f√ºr `/var/log/rtl-ogn/` (`/etc/tmpfiles.d/rtl-ogn.conf`)
  - Effekt: Verzeichnis wird automatisch bei jedem Boot angelegt
- **RTL-SDR Blog Library v1.3.6 installiert:** Behebt "[R82XX] PLL not locked" Problem mit R828D-Tuner (2026-01-29)
  - Alte Debian librtlsdr (0.6.0-4 aus 2012) durch aktuelle RTL-SDR Blog Version ersetzt
  - Kompiliert und installiert nach `/usr/local/lib/` (√ºberschreibt System-Paket)
  - ogn-rf und rbfeeder nutzen jetzt V4-optimierte Library
  - PLL-Lock-Meldungen nur noch w√§hrend Initialisierung, danach stabil
  - Update-Check im Wartungsskript integriert (pr√ºft auf neue Versionen)
  - Quelle: https://github.com/rtlsdrblog/rtl-sdr-blog
- **AtomS3 Firmware reflashed:** drone-mesh-mapper esp32s3-dual-rid.bin (2026-01-30)
  - Problem: Charge-Only USB-Kabel (0% health, keine D+/D-) verhinderte USB-Kommunikation
  - L√∂sung: Geschirmtes USB3-Kabel (109mŒ©, 100% health) + Firmware-Reflash
  - Alte Firmware war korrupt ("Invalid image block, can't boot")
  - Neue Firmware: /home/pi/drone-mesh-mapper/firmware/esp32s3-dual-rid.bin (1.4 MB)
  - USB jetzt stabil (0 Disconnects), zmq-decoder funktional
  - Update-Check im Wartungsskript integriert (pr√ºft auf neue Commits)
  - Quelle: https://github.com/colonelpanichacks/drone-mesh-mapper
  - **REGRESSION (2026-02-01):** USB-Instabilit√§t zur√ºckgekehrt seit 07:35 Uhr (1506 Fehler/24h) - Hardware-Check ausstehend
- **claude-respond.service Timeout erh√∂ht (2026-02-01):**
  - Problem: Service timeout nach 10 Minuten (zu kurz f√ºr vollst√§ndige Wartung)
  - Fix: TimeoutSec 600s ‚Üí 1800s (30 Minuten)
  - Verhindert SIGTERM w√§hrend laufender Wartung
- **mtp-probe Log-Spam behoben (2026-02-01):**
  - Problem: mtp-probe pr√ºft AtomS3 bei jedem USB-Reconnect (f√ºllt user.log)
  - Fix: udev-Regel `/etc/udev/rules.d/99-disable-mtp-atomS3.rules` (ENV{MTP_NO_PROBE}="1" f√ºr VID:303a PID:1001)
  - Effekt: Reduziert Log-Spam bei USB-Instabilit√§t erheblich
- **logrotate Duplicate-Eintr√§ge behoben (2026-02-02):**
  - Problem: /var/log/syslog + kern.log in zwei Config-Dateien (rsyslog + rsyslog-tmpfs)
  - Fix: Aus /etc/logrotate.d/rsyslog entfernt (rsyslog-tmpfs verwaltet diese)
  - Effekt: logrotate.service l√§uft wieder ohne Fehler
- **telegram-bot Legacy-Pfade aktualisiert (2026-02-02):**
  - Problem: /var/run ist deprecated (systemd warnt)
  - Fix: /var/run ‚Üí /run in Service-Unit + Skripten (telegram-bot-daemon, telegram-ask)
  - Effekt: Keine systemd-Warnings mehr
- **claude-respond-to-reports Kontext-Verbesserungen (2026-02-02):**
  - **System State Capture:** Erfasst laufende Services, Serial Port Status, ZMQ Ports vor Claude-Ausf√ºhrung
  - **Kritische Regeln:** 5 MANDATORY Regeln f√ºr atoms3-proxy, Serial Port, Service-Checks im Prompt
  - **Automatisches Context-Loading:** `--files` Flag l√§dt CLAUDE.md + ATOMS3-PROXY.md + ATOMS3-FIRMWARE.md automatisch
  - **Post-Repair Verification:** Pr√ºft atoms3-proxy, dragonsync, wifi-presence-detector, zmq-decoder nach Wartung
  - **Auto-Recovery:** Versucht automatischen Restart wenn Services nach Wartung ausgefallen sind
  - **Problem gel√∂st:** Verhindert fatale Reparaturen (z.B. atoms3-proxy Restart w√§hrend Datenverarbeitung)
  - **Backup:** `/usr/local/sbin/claude-respond-to-reports.backup-20260202-*`
- **GPS RTK Base Station + PPS Zeitsynchronisation (2026-02-03):**
  - **Hardware:** Waveshare LC29H Dual-Band GPS (L1+L5), RTL-SDR V4 f√ºr 868 MHz
  - **PPS PIN KORRIGIERT:** GPIO 18 (Pin 12), NICHT GPIO 4! - Via GPIO-Scan identifiziert (Doku war falsch)
  - **PPS:** Direct kernel access via `/dev/pps0`, Pull-Up essentiell (Open-Drain Output)
  - **Genauigkeit:** Sub-Nanosekunden (¬±356ns, Offset +2.8ns)
  - **Stratum:** System operiert als Stratum 1 (prim√§re Zeitquelle)
  - **RTK Base Station:** Fixed Mode nach Survey-In (10min, 2m Genauigkeit)
  - **NTRIP Caster:** Port 5000, Mountpoint `/BASE`, RTCM-Stream 4.7 kbps
  - **Position:** Message 1005 (ECEF Koordinaten), NMEA unterdr√ºckt im Base Mode (Design, kein Bug)
  - **Chrony Config:** `refclock PPS /dev/pps0 refid PPS poll 4 prefer offset 0.102`
  - **Tools:** `/usr/local/sbin/gps-tools/` (extract_base_position.py, enable_pps.py, gps-safe-check)
  - **Monitoring:** ntripcaster in feeder-watchdog, telegram-bot, claude-respond integriert
- **NTRIP Source Table Proxy (2026-02-03):** L√∂st "empty source table" Problem f√ºr NTRIP-Client-Apps
  - **Problem:** str2str sendet fast leere Source Table (`STR;BASE;`) - Apps wie Lefebure NTRIP Client finden keinen Mountpoint
  - **L√∂sung:** Python-Proxy auf Port 5001, erg√§nzt vollst√§ndige Source Table f√ºr `GET /`, leitet `GET /BASE` transparent zu str2str Port 5000
  - **Service:** `ntrip-proxy.service` (User: pi, Port 5001)
  - **Architektur:** Client ‚Üí Port 5001 (Proxy: Source Table) ‚Üí Port 5000 (str2str: RTCM-Stream)
  - **Source Table:** Vollst√§ndige NTRIP-konforme Metadaten (Stegaurach, RTCM 3.2, GPS+GLO+GAL, Position)
  - **Transparent Proxy:** Mountpoint-Requests werden 1:1 weitergeleitet (keine HTTP-Modifikation)
  - **Monitoring:** In feeder-watchdog, telegram-bot, claude-respond integriert (27 Services total)
  - **Dokumentation:** `~/docs/GPS-NTRIP-PROXY.md`
  - **Dokumentation:** `~/docs/GPS-RTK-HYBRID-SETUP.md` vollst√§ndig aktualisiert
  - **Status:** ‚úÖ Stratum 1 aktiv, NTRIP l√§uft, Rover k√∂nnen RTK-Korrekturen abrufen
- **zmq-decoder entfernt, atoms3-proxy Migration abgeschlossen (2026-02-03):**
  - **Problem:** Watchdog √ºberwachte noch zmq-decoder (Service existiert seit 2026-02-02 nicht mehr)
  - **Eskalationen:** 6 Versuche in 5 Stunden, da zmq-decoder durch atoms3-proxy ersetzt wurde
  - **Fix feeder-watchdog:** check_atoms3() Funktion komplett entfernt
  - **Fix claude-respond:** USB-Fehler-Z√§hlung korrigiert (TOTAL_COUNT hatte "0\n0" wegen `|| echo "0"`)
  - **Grund:** `grep -c` gibt IMMER eine Zahl zur√ºck, `|| echo "0"` ist √ºberfl√ºssig und verursacht doppelte Ausgabe
  - **Effekt:** Keine falschen Eskalationen mehr, USB-Statistik funktioniert korrekt
- **Telegram /errors - Intelligente Fehleranalyse (2026-02-04):**
  - **Backend:** `/usr/local/sbin/error-troubleshooter` - Sammelt journalctl Errors, analysiert mit Claude
  - **Actions:** analyze (timeframe), check-service (health), usb-stats (disconnects), restart-service
  - **Telegram Integration:** Inline Keyboard mit 5 Buttons (Details, Auto-Fix, Service-Check, USB-Stats, Abbrechen)
  - **Callback Handler:** Verarbeitet Button-Klicks, speichert Kontext in `/run/telegram-errors-context.json`
  - **Intelligente Klassifikation:** Keine Errors (stabil), Harmlose Errors (collectd RRD), Echte Probleme (Top 3 mit Actions)
  - **Claude-Prompt:** Kurze pr√§gnante Analyse, ignoriert bekannte harmlose Warnungen
  - **Command Lock:** Erweitert um /errors (3 Sekunden Doppel-Request-Schutz)
  - **Bugfixes:** Command Lock trap statement, Exit Code Check, JSON Parsing mit Fallbacks
  - **Status:** ‚úÖ Produktiv - Erm√∂glicht schnelle Fehlerdiagnose via Telegram mit interaktiven Buttons
- **Telegram /flugzeug - Flugzeugdetails nachschlagen (2026-02-04):**
  - **Backend:** `/usr/local/sbin/aircraft-lookup` - ICAO hex ‚Üí Stammdaten + Live-Tracking
  - **Datenquellen:** readsb aircraft.json (Live) + tar1090 aircraft.csv (Stammdaten)
  - **Ausgabe:** Registration, Typ, Beschreibung, Callsign, H√∂he, Speed, Track, Position, RSSI, Squawk, Emergency
  - **Features:** Automatische Normalisierung, Format-Validierung, Emergency-Anzeige (üü¢/üî¥), metrisch + imperial
  - **tar1090 Integration:** Direkt-Link zum Flugzeug in Karte
  - **Command Lock:** 3 Sekunden Doppel-Request-Schutz
  - **Status:** ‚úÖ Produktiv - Schnelle Flugzeugabfrage via Telegram
- **Telegram /service - Service-Diagnose (2026-02-04):**
  - **Backend:** `/usr/local/sbin/service-info` - systemd Service-Status + Details
  - **Zwei Modi:** Ohne Parameter (Liste aller 29 Services mit Ampeln), Mit Parameter (detaillierte Diagnose)
  - **Liste-Modus:** Kategorisiert nach Core, Feeds, MLAT, Web, OGN, DragonSync, Alerts, GPS - Status-Icons üü¢/üî¥/‚ö´/üü°
  - **Detail-Modus:** Status, Enabled, PID, Uptime, Restart-Count, Memory, Tasks, Result, Exit-Code, letzte Logs
  - **Features:** Uptime-Formatierung (d/h/m), Problem-Diagnose (Result/Exit bei failed), Log-Auszug (letzte Zeilen)
  - **Command Lock:** 3 Sekunden Doppel-Request-Schutz
  - **Status:** ‚úÖ Produktiv - Schnelle Service-Diagnose ohne SSH

- **Telegram /gps - GPS/RTK Status (2026-02-04):**
  - **Backend:** `/usr/local/sbin/gps-status` - Non-invasive GPS monitoring (GPS-Device blockiert durch str2str)
  - **Datenquellen:** chrony (PPS), systemd (Services), ntripcaster (Clients/Uptime), Heuristik (Satelliten)
  - **PPS:** Stratum, Offset, Samples, System Time (Nanosekunden-Genauigkeit)
  - **Satelliten:** Sch√§tzung 12-20 (Multi-GNSS: GPS L1+L5, GLONASS, Galileo, BeiDou, QZSS)
  - **GNSS:** Almanach, Ephemeris (inferiert aus Stratum 1), A-GPS Status
  - **NTRIP:** Base Station (49.86625, 10.83948, 283m), Clients, Uptime
  - **Services:** ntripcaster, ntrip-proxy, chronyd, gps-mqtt-publisher (Status-Icons üü¢/üî¥)
  - **Software:** RTKLIB str2str (installed), chrony (4.3), gpsd (3.22)
  - **Hardware:** Waveshare LC29H (Dual-Band RTK), /dev/ttyAMA0 (UART), /dev/pps0 (GPIO 18)
  - **Features:** Sub-Nanosekunden PPS-Offset, RTK Fixed Position, Multi-GNSS Support, 24/7 Almanach aktuell
  - **Bugfix:** str2str Version-Check entfernt (h√§ngt ohne Parameter), nur "installed" Check
  - **Status:** ‚úÖ Produktiv - Vollst√§ndiger GPS-√úberblick ohne Device-Zugriff

### Bugfixes (2026-02-04)
- **Telegram Command Lock trap statement:** `trap 'rm -f "''"' RETURN` ‚Üí `trap "rm -f \"$lock_file\"" RETURN`
  - Problem: Variable $lock_file wurde nicht expandiert, Lock-Files blieben liegen
  - Fix: Double-Quotes f√ºr korrekte Variable-Expansion
- **error-troubleshooter Exit Code Check:** `if [ $? -ne 0 ]` nach command substitution
  - Problem: `$?` pr√ºfte falschen Exit Code (immer 0 bei Variable-Zuweisung)
  - Fix: `if [ -z "$analysis" ] || ! echo "$analysis" | jq -e . >/dev/null 2>&1`
- **TELEGRAM Tag Parsing Bug:** Claude setzte Markdown `###` vor `[TELEGRAM:OK]`
  - Problem: Parser extrahierte "###" statt Nachricht bei getrennten Zeilen
  - Root Cause: `grep '[TELEGRAM:OK]' | sed 's/\[TELEGRAM:OK\]//' | head -1` matched nur erste Zeile
  - Fix: Robustes Parsing mit grep -A 10, filtert # und leere Zeilen, nimmt n√§chste Content-Zeile
  - Fallback: Tag in derselben Zeile (sed extrahiert nach Tag, entfernt Markdown-Prefixes)
  - Prompt Fix: "WICHTIG: Tag MUSS am Zeilenanfang stehen, OHNE Markdown-Prefix"
  - Test: Alle 5 Edge-Cases funktionieren (getrennte Zeilen, in einer Zeile, mit ###, multiline, Leerzeilen)
- **Telegram Bot Migration zu Markdown V2 (2026-02-04):**
  - **Problem:** Telegram API Markdown (V1) ist deprecated, Markdown V2 hat strengere Escaping-Regeln
  - **Migration:** `parse_mode="Markdown"` ‚Üí `parse_mode="MarkdownV2"` in send_message_raw()
  - **Escaping:** Neue `escape_markdown_v2()` Funktion escaped 18 Sonderzeichen: `_ * [ ] ( ) ~ \` > # + - = | { } . !`
  - **Bash-Fallen behoben:**
    - Backticks sind KEINE Markdown-Escapes, sondern Bash Command Substitution (fatal!)
    - Curly Braces `{}` k√∂nnen nicht mit Bash Parameter Expansion escaped werden ‚Üí sed verwendet
  - **Text-Literale:** Alle statischen Texte in Messages m√ºssen ebenfalls escaped werden (nicht nur Variablen)
  - **GPS-Message:** Alle 21 Variablen + Text-Literale korrekt escaped (Klammern, Bindestriche, Ampersand)
  - **Funktionstest:** `/tmp/test-escape-markdown-v2.sh` validiert alle Sonderzeichen
  - **Status:** ‚úÖ Produktiv - Alle Nachrichten nutzen jetzt Markdown V2

### Skript-Security Audit (2026-01-25)
**Peer Review aller eigenen Skripte in `/usr/local/sbin/`**
**W√∂chentliches automatisches Audit:** Integriert in Wartung, Marker: `/var/lib/claude-pending/last-security-audit`

#### Kritisch behoben
| Skript | Problem | Fix |
|--------|---------|-----|
| telegram-secretary | Command Injection via User-Input | `sanitize_for_prompt()` entfernt Shell-Konstrukte |
| do-queue-worker | Race Condition bei Queue-Zugriff | `flock` f√ºr atomares Locking |
| sd-health-check | Source-Injection via stats.dat | Sichere Extraktion mit `grep`/`cut` |
| update-dns-fallback | Temp-File mit falschen Permissions | `chmod 644` vor `mv` |

#### Medium behoben
| Problem | Fix | Betroffene Skripte |
|---------|-----|-------------------|
| `source` Config kann Code ausf√ºhren | Sichere grep/cut Extraktion | 10 Skripte |
| Log-Rotation ohne chmod | `chmod 644` vor `mv` | feeder-watchdog |
| Session-File kurz ohne Permissions | `umask 077 && touch` vor Schreiben | telegram-ask |
| Path-Traversal via Config-Eintr√§ge | `validate_entry()` pr√ºft auf `..` und `/` | log-persist |

#### Low behoben
| Problem | Fix | Betroffene Skripte |
|---------|-----|-------------------|
| Curl ohne Timeout | `--max-time 10` | 7 Skripte |
| Fehlende Log-Rotation | Max 500-1000 Zeilen, dann truncate | telegram-ask, sd-health-check, do-queue-worker |
| Pipe-Fehler nicht erkannt | `set -o pipefail` | 9 Skripte |

### WiFi Presence Detection + AtomS3 Proxy (2026-02-02)
**Status:** ‚úÖ **PRODUKTIV** - Proxy-Architektur l√∂st Serial-Port-Konflikt

WiFi-basierte Anwesenheitserkennung via IEEE 802.11 Probe Requests vollst√§ndig implementiert mit ZMQ-basiertem Routing-Proxy.

**Problem gel√∂st:**
- **Root Cause:** Mehrere Prozesse k√∂nnen NICHT gleichzeitig denselben Serial Port lesen
- **Symptom:** "device disconnected" nach 2-3 Minuten (NICHT Hardware-Problem!)
- **Diagnose:** `lsof /dev/ttyACM0` zeigte DragonSync + wifi-presence-detector im Konflikt
- **L√∂sung:** atoms3-proxy = Single Serial Reader + ZMQ Broadcast

**Architektur (Proxy Pattern):**
```
AtomS3 (/dev/remoteid, 115200 baud)
  ‚Üì Serial JSON: {"type":"remoteid",...} oder {"type":"probe",...}
atoms3-proxy.service (Single Serial Reader, exklusiver Port-Zugriff)
  ‚îú‚îÄ type="remoteid" ‚Üí ZMQ PUB Port 4224 ‚Üí DragonSync ‚Üí MQTT/HA
  ‚îî‚îÄ type="probe"    ‚Üí ZMQ PUB Port 4225 ‚Üí wifi-presence-detector ‚Üí Telegram
```

**Vorteile der Proxy-Architektur:**
- ‚úÖ Saubere Trennung (Single Responsibility)
- ‚úÖ Kein Serial-Port-Konflikt (nur EIN Reader)
- ‚úÖ ZMQ PUB/SUB Pattern (broadcast zu N Consumern)
- ‚úÖ Services k√∂nnen unabh√§ngig neu starten (kein Port-Lock)
- ‚úÖ Einfach erweiterbar (neue Consumer via ZMQ Subscribe)
- ‚úÖ Non-blocking sends (langsamer Consumer blockiert nicht Proxy)

**Komponenten:**

| Service | Funktion | Port | Status |
|---------|----------|------|--------|
| **atoms3-proxy** | Serial ‚Üí ZMQ Router | 4224, 4225 | ‚úÖ Active (22 Services total) |
| **DragonSync** | Remote ID ‚Üí MQTT | 8088 (API) | ‚úÖ Active |
| **wifi-presence-detector** | Probe ‚Üí Telegram | - | ‚úÖ Active |
| ~~zmq-decoder~~ | *(redundant, entfernt)* | - | üóëÔ∏è Disabled |

**Stabilit√§t (Live-Test 33+ min, 2026-02-02):**
- ‚úÖ 0 USB-Disconnects (vorher: alle 2-3 min "device disconnected")
- ‚úÖ 100+ Probe Requests geroutet (~10/min, Residential normal)
- ‚úÖ 0 Remote ID messages (keine Drohnen in Range)
- ‚úÖ 0 Fehler in journalctl
- ‚úÖ Beide Consumer empfangen stabil

**Erkannte Ger√§te (in `/var/lib/claude-pending/known-devices.json`):**

| MAC | Hersteller | Beschreibung | Status |
|-----|------------|--------------|--------|
| `4C:A1:61:09:23:3C` | Rain Bird Corp | Nachbar Bew√§sserungssystem (sucht "Schneider.Net") | Dokumentiert |
| `2C:CF:67:75:15:AB` | Raspberry Pi | Controme Smart-Heat-OS (IP .71, Raum darunter) | Whitelisted |
| `88:A2:9E:7D:B3:5B` | Raspberry Pi | Dieses System (WLAN DOWN) | Whitelisted |
| `B0:E9:FE:A7:EE:EC` | Woan Technology | **MYSTERY** - IoT-Ger√§t, sucht "LEWI", -63 dBm | Unter Beobachtung |
| `8C:C5:D0:20:DC:46` | Samsung | Smartphone/Tablet, -79 dBm | Dokumentiert |
| `04:56:E5:E2:1E:13` | Intel Corporate | Laptop/PC, -74 dBm | Dokumentiert |

**Service-Setup:**
- `/usr/local/sbin/atoms3-proxy` - Serial ‚Üí ZMQ Router (Python, User: pi)
- `/usr/local/sbin/wifi-presence-detector` - ZMQ Consumer + Filtering (Python)
- `/etc/wifi-presence-detector.conf` - Konfiguration
  - ssid_blacklist: LEWI, Gast
  - mac_whitelist: 2C:CF:67:75:15:AB (Controme), 88:A2:9E:7D:B3:5B (dieses System)
  - rssi_threshold: -70 dBm, min_sightings: 3, cooldown: 4h
- OUI Database: 38.828 Hersteller (SQLite, in-memory caching)
- Known Devices: Proaktive Dokumentation externer Ger√§te f√ºr Reports

**Dokumentation:**
- `~/docs/PRESENCE-DETECTION.md` - WiFi Presence Detection System
- `~/docs/ATOMS3-PROXY.md` - **NEU:** Proxy Architecture & Troubleshooting
- `~/docs/ATOMS3-FIRMWARE.md` - ESP32 Firmware (korrigiert: USB-Stabilit√§t war IMMER da!)

**USB-Stabilit√§t - WICHTIGE KORREKTUR:**
- ‚úÖ **Hardware war IMMER stabil** (geschirmtes USB3-Kabel 109mŒ©, 100% health)
- ‚ùå **"USB disconnect" Fehler waren SOFTWARE-Konflikt** (Serial Port Contention)
- ‚úÖ Firmware l√§uft stabil (esp32s3-dual-rid.bin mit PSRAM-Support)
- ‚úÖ Serial Monitoring Timing gel√∂st (ARDUINO_USB_CDC_ON_BOOT=1)
- ‚úÖ Proxy hat Auto-Reconnect (exponential backoff 5s ‚Üí 60s)

### System
- zram swap, tmpfs /var/log, Log-Persistenz
- NTP: PTB Stratum-1 mit NTS + GPS PPS (2026-02-03)
  - **PPS-basierte Zeitsynchronisation:** Sub-Nanosekunden-Genauigkeit (¬±356ns, Offset +2.8ns)
  - Direct kernel access via `/dev/pps0` (keine gpsd SHM overhead)
  - Waveshare LC29H Dual-Band GPS (L1+L5) auf **GPIO 18 (Pin 12)** - Schaltplan hatte GPIO 4 falsch!
  - UART auf GPIO 14/15 (Pins 8/10), PPS braucht Pull-Up (Open-Drain)
  - Stratum 1 Operation (System ist prim√§re Zeitquelle)
  - Chrony: `offset 0.102` kompensiert 100ms PPS-Puls
  - Monitoring: Telegram /status + daily-summary zeigen PPS-Status
  - MLAT-Verbesserung: Optimal timestamps f√ºr Position-Berechnungen
  - Dokumentation: `~/docs/GPS-SETUP.md`
- **GPS RTK Base Station Mode (2026-02-03):** Nur RTCM f√ºr NTRIP (NMEA unterdr√ºckt im Fixed Mode)
  - **Baudrate:** 115200 (Base Mode sendet nur RTCM, kein NMEA)
  - **NTRIP Caster:** str2str ntripc auf Port 5000 (Mountpoint /BASE) f√ºr SW Maps/Rover
  - **Base Station:** Fixed Mode nach Survey-In (600s, 2m Genauigkeit)
  - **Position:** RTCM Message 1005 (ECEF Koordinaten), extrahierbar mit pyrtcm
  - **Kein Hybrid Mode:** LC29H(BA) unterdr√ºckt NMEA im Fixed Mode - das ist Firmware-Design!
  - **PPS funktioniert trotzdem:** PAIR753 aktiviert PPS auch ohne NMEA
  - Dokumentation: `~/docs/GPS-RTK-HYBRID-SETUP.md`
- Hardware-Watchdog (90¬∞C Shutdown)
- Raspberry Pi Connect

### OGN/FLARM Integration (2026-01-29) - procServ-√úberwachung
*Hardware aktiviert 2026-01-29, Software l√§uft stabil mit procServ* ‚Üí `docs/OGN-SETUP.md`

**‚úÖ Station "SteGau" voll funktional!**

| Komponente | Status |
|------------|--------|
| Hardware | ‚úÖ RTL-SDR Blog V4 auf USB 3.0 (Serial 00000001) |
| ogn-rf | ‚úÖ **Stabil** (selbst kompiliert v0.2.6) auf Port 8080 |
| ogn-decode | ‚úÖ **Stabil** (precompiled v0.3.2) auf Port 8081 |
| ogn-rf-procserv | ‚úÖ Active - telnet-√ºberwacht auf Port 50000 |
| ogn-decode-procserv | ‚úÖ Active - telnet-√ºberwacht auf Port 50001 |
| Port 50010 | ‚úÖ TCP-Socket ogn-rf ‚Üí ogn-decode funktioniert |
| ogn2dump1090 | ‚úÖ Active - empf√§ngt zus√§tzlich APRS von glidernet.org |
| readsb Port 30008 | ‚úÖ SBS-Jaero-In konfiguriert |
| OGN-DDB | ‚úÖ 34.171 Eintr√§ge, w√∂chentliches Update |
| tar1090 OGN-Tracks | ‚úÖ Segelflugzeuge mit `~` Pr√§fix |
| **APRS-Upload** | ‚úÖ Station "SteGau" verified auf GLIDERN3/5 |
| **Station-URL** | ‚úÖ http://live.glidernet.org/receiver-status/?id=SteGau |

**Architektur (Dual-Path mit procServ):**
```
1. RF-Empfang ‚Üí Community-Upload:
   RTL-SDR V4 (868 MHz)
     ‚Üì
   ogn-rf-procserv (Port 50000, HTTP 8080)
     ‚Üì TCP Socket localhost:50010
   ogn-decode-procserv (Port 50001, HTTP 8081)
     ‚Üì APRS
   glidernet.org (GLIDERN3/5)

2. Community-Empfang ‚Üí tar1090:
   glidernet.org APRS
     ‚Üì 100km-Filter
   ogn2dump1090
     ‚Üì SBS zu Port 30008
   readsb ‚Üí tar1090 (OGN-Tracks mit `~` Pr√§fix)
```

**Konfiguration:**
- **RF.PipeName** = `:50010` (Server mit Colon-Pr√§fix)
- **Demodulator.PipeName** = `localhost:50010` (Client ohne f√ºhrenden Colon)
- **procServ:** Erm√∂glicht telnet-Zugriff und automatisches Restart bei Problemen

**‚ö†Ô∏è KRITISCH: FFTW Benchmarking bei JEDEM Start (2026-01-29)**

Das Benchmarking passiert **bei JEDEM Service-Start**, nicht nur einmalig!

| Aspekt | Details |
|--------|---------|
| **Dauer** | 10-15 Minuten (CPU ~90-95%) |
| **Grund** | ogn-rf nutzt **kein** FFTW Wisdom-System (kein import_wisdom im Code) |
| **Symptom** | Service scheint "h√§ngen", Ports √∂ffnen erst nach Benchmarking |
| **Auswirkung** | Jeder Restart = 15 Minuten Ausfallzeit |
| **Timeout-Schutz** | `TimeoutStartSec=20m` in Service-Unit |
| **Watchdog-L√∂sung** | ‚úÖ Pr√ºft Port 8080, erkennt Benchmarking (hohe CPU), keine False-Positives! |
| **FFTW Wisdom** | ‚ùå Hilft NICHT (ogn-rf l√§dt keine Wisdom-Dateien) |

**Status pr√ºfen w√§hrend Benchmarking:**
```bash
# Port 8080 erreichbar = Benchmarking abgeschlossen
curl -s http://localhost:8080/status.html | grep "Software"
```

**Andere Debugging-Erkenntnisse:**
- "[R82XX] PLL not locked!" Warnungen sind normal beim Gain-Stepping
- "Error while syncing/reading" bedeutet keine RF-Signale (normal nachts)

**Status pr√ºfen:**
```bash
systemctl status ogn-rf-procserv ogn-decode-procserv ogn2dump1090
ss -tlnp | grep -E "8080|8081|50010"  # HTTP- und Data-Ports
curl -s http://localhost:8081/status.html | grep "Aircrafts received"
sudo tail -20 /var/log/rtl-ogn/ogn-decode.log | grep verified
```

**Reichweite:**
- **RF-Upload:** Eigene Empf√§nge (~100 km bei guten Bedingungen)
- **APRS-Empfang:** 100km-Radius um Stegaurach via ogn2dump1090
- **Live-Tracking:** http://live.glidernet.org/receiver-status/?id=SteGau

**Monitoring:**
- Watchdog: OGN Health Check mit Port 8080-Abfrage (erkennt Benchmarking)
- Telegram /status: Service-Status + Empfang/min
- Telegram /stats: Detaillierte OGN-Statistiken (Empfang/min, /Stunde)
- daily-summary: OGN Gesamt (12h)
- Alle 21 Services √ºberwacht

---

### Intelligentes Aircraft-Alert-System (2026-02-03)
**Status:** ‚úÖ Vollst√§ndig implementiert und aktiv

Automatische ICAO-Code-Recherche f√ºr unbekannte Flugzeuge mit 30-Tage-Cache.

#### Problem gel√∂st:
- ‚ùå Vorher: 3C-3F Range = Milit√§r ‚Üí Glider 3DE527 falsch erkannt als Milit√§r
- ‚ùå tar1090 HTTP 502 Error unbemerkt vom Watchdog
- ‚ùå Keine US Military Erkennung
- ‚ùå 20km Reichweite (zu weit, nicht optisch sichtbar)

#### Komponenten:

**1. ICAO Lookup Service** (`/usr/local/sbin/icao-lookup-service`)
- 30-Tage Cache mit automatischem Ablauf (f√ºr Military Code Rotation)
- Lokale Erkennung via tar1090 ranges.json (32 Military Ranges)
- Web-Lookup mit ADSBexchange Database Integration
- Fallback: ICAO Range Allocation (Land-Erkennung)
- Automatische Telegram-Benachrichtigung mit Recherche-Ergebnissen
- CLI-Interface f√ºr manuelle Abfragen

**2. tar1090 HTTP Health Check** (feeder-watchdog v2.2)
- Erkennt HTTP 502 Errors (nicht nur systemd Service-Status)
- Automatischer Restart von lighttpd + tar1090
- Exponentieller Backoff (5min ‚Üí 160min)
- Telegram-Benachrichtigung bei Problemen
- Backup: `/usr/local/sbin/feeder-watchdog.backup-*`

**3. Auto-Update Service** (t√§glich 04:00 Uhr)
- systemd timer: `update-military-icao.timer`
- Aktualisiert tar1090 git-db
- Regeneriert Military ICAO Patterns aus ranges.json
- Restart aircraft-alert-notifier mit neuen Patterns
- Log: `/var/log/military-icao-update.log`
- **Bonus:** US Military Codes (AD, AE, AF) jetzt auch erkannt!

**4. Military ICAO Pattern Generator** (`/usr/local/sbin/military-icao-updater`)
- Auto-generiert Patterns aus tar1090 ranges.json
- Output: `/var/lib/claude-pending/military-icao-patterns.py`
- Erweitert auf US + German + weitere L√§nder

#### Dateien:
```
/usr/local/sbin/icao-lookup-service           # Hauptservice mit Web-Recherche
/usr/local/sbin/update-military-icao          # Update-Skript (t√§glich 04:00)
/usr/local/sbin/military-icao-updater         # Pattern-Generator
/usr/local/sbin/feeder-watchdog               # v2.2 mit tar1090 HTTP Check
/etc/systemd/system/update-military-icao.{service,timer}
/var/lib/claude-pending/icao-lookup-cache.json       # 30-Tage Cache
/var/lib/claude-pending/military-icao-patterns.py    # Auto-generierte Patterns
/var/log/military-icao-update.log                    # Update-Log
```

#### Test-Results:
```bash
# Ziviler Glider (war vorher falsch als Milit√§r erkannt)
/usr/local/sbin/icao-lookup-service 3DE527
# ‚Üí Germany, Zivil ‚úÖ (korrekt!)

# Deutsches Milit√§r
/usr/local/sbin/icao-lookup-service 3E96CB
# ‚Üí Germany, Milit√§r ‚úÖ

# US Military (neu!)
/usr/local/sbin/icao-lookup-service AE0004
# ‚Üí USA, Milit√§r ‚úÖ
```

#### Verbesserungen:
| Vorher | Nachher |
|--------|---------|
| 3C-3F = Milit√§r (zu breit) | Pr√§zise Patterns nur f√ºr bekannte Military |
| Keine US Military | US + German + weitere L√§nder |
| 20km Reichweite | 10km (optisch sichtbar) |
| Manuelle Updates | Automatisch t√§glich 04:00 |
| tar1090 502 unbemerkt | Watchdog erkennt HTTP-Probleme |
| Unbekannte Codes: Keine Info | Auto-Recherche + 30d Cache |

**Dokumentation:** `~/docs/AIRCRAFT-ALERTS.md`, `~/docs/AIRCRAFT-ALERT-TODO.md`

---

### WiFi Presence Detection Optimierungen (2026-02-03)

**Problem:** Keine Telegram-Benachrichtigungen, Ger√§te nicht erkannt

**Fixes:**
1. **Whitelist-Format korrigiert:**
   - Erstellt: `/var/lib/claude-pending/wifi-whitelist.json`
   - Format: `{"macs": [...]}` statt `{"devices": {...}}`
   - Effekt: 8 MACs erfolgreich geladen (vorher 0)

2. **RSSI-Threshold optimiert:**
   - `-70 dBm` ‚Üí `-90 dBm` (maximal empfindlich)
   - Erkennt jetzt Ger√§te 2 Stockwerke entfernt
   - Rain Bird Bew√§sserungssystem bei -90 dBm erkannt (Nachbar, maximale Reichweite)

3. **Google Home Mystery gel√∂st:**
   - 48:D6:D5:67:D1:B9 - 03:13 AM Burst (60 Probes/Min)
   - Test: Power-Cycle best√§tigt gleiche MAC
   - Ursache: Firmware-Update Recovery Mode
   - Normal: Moderate Probe Rate
   - Whitelisted

**Dokumentierte Ger√§te:**
```
4C:A1:61:09:23:3C - Rain Bird Bew√§sserungssystem (Nachbar, -90 dBm)
2C:CF:67:75:15:AB - Controme Smart-Heat-OS (Raum darunter)
88:A2:9E:7D:B3:5B - Dieses System (WLAN DOWN)
B0:E9:FE:A7:EE:EC - SwitchBot Smart Home (-64 dBm, 2 Stockwerke!)
8C:C5:D0:20:DC:46 - User Smartphone (Samsung, -28 dBm nah)
00:03:7F:12:34:56 - Devolo WiFi Mesh (Site Survey Modus, ~1.5 Probes/h)
48:D6:D5:67:D1:B9 - Google Home (2 Stockwerke, -68 dBm, Recovery Mode Incident)
C8:2E:18:0C:40:C0 - Shelly Plus Plug S (Yunas Zimmer)
```

**Dateien:**
- `/var/lib/claude-pending/wifi-whitelist.json` - Korrigiertes Format
- `/var/lib/claude-pending/known-devices.json` - Dokumentation mit Kontext
- `/etc/wifi-presence-detector.conf` - RSSI -90 dBm

**Dokumentation:** `~/docs/PRESENCE-DETECTION.md`

---

### System-Konfiguration (2026-02-03)

**Hostname Fix:** `/etc/hosts`
- System kannte eigenen Namen `adsb-feeder.internal` nicht
- Fix: `127.0.1.1  adsb-feeder adsb-feeder.internal`
- Effekt: System kann sich selbst unter `.internal` erreichen
- Home Assistant: DNS im Router korrigiert f√ºr externe Erreichbarkeit

**Test:**
```bash
getent hosts adsb-feeder.internal
# ‚Üí 127.0.1.1 ‚úÖ

curl http://adsb-feeder.internal/tar1090/
# ‚Üí HTTP 200 OK ‚úÖ
```

---


## 2026-02-06 - Wartungs-Watchdog: Fix Timing-Issue bei Session-Archivierung

### Problem
Nach Archivierung einer PENDING-Session l√∂ste der Watchdog f√§lschlicherweise eine Diagnose aus:
1. 08:02: Watchdog pr√ºft ‚Üí "Exit 1 mit PENDING-Session ‚Üí OK" ‚úÖ
2. 08:08: Session wird als ABGELEHNT archiviert (durch User-Entscheidung)
3. 08:12: Watchdog pr√ºft erneut ‚Üí Sieht alten "[FEHLER] Exit 1" von 07:30 ‚Üí Session existiert NICHT mehr ‚Üí Denkt es ist neuer Fehler ‚Üí Startet Diagnose

**Root Cause:**
Der Watchdog erkannte nicht, dass eine Session als "rejected" archiviert wurde. Die `check_recent_errors()` Funktion pr√ºfte nur auf "Korrektur abgeschlossen|behoben|GEFIXT", aber nicht auf Session-Archivierung.

### L√∂sung
1. **Log-Markierung:** "Korrektur abgeschlossen: SSH-H√§rtung 3x abgelehnt" ins Wartungslog geschrieben
2. **Watchdog erweitert:** `check_recent_errors()` erkennt jetzt auch:
   - `SESSION.*BEHANDELT`
   - `archiviert`
   - `Session.*rejected`

### Ge√§ndert
- `/usr/local/sbin/wartungs-watchdog`: Erweiterte behandelt-Keywords (Zeile 145)

**Test:**
```bash
‚úì Fehler gefunden im Log
‚úì Fehler wurde behandelt (erkannt)
‚Üí Watchdog wird KEINE Diagnose starten
```

**Status:** ‚úÖ Watchdog erkennt Session-Archivierung als "behandelt"


## 2026-02-06 - wait_for_quiet: Fix Henne-Ei-Problem (Wartung wartete auf sich selbst)

### Problem
Die Wartung wartete **10 Minuten auf sich selbst** (07:02-07:12):
- `claude-respond.service` ist Type=oneshot
- W√§hrend das Skript l√§uft: Status = **activating**
- `wait_for_quiet()` Check 1 pr√ºft auf aktivierende Services
- Findet: `claude-respond.service` (sich selbst!)
- Wartet 10 Minuten ‚Üí Timeout ‚Üí Startet trotzdem

**Symptom:**
```
[07:02:18] ‚è≥ Warte auf Ruhe (0s/600s): Services starten: claude-respond.service
[07:02:33] ‚è≥ Warte auf Ruhe (15s/600s): Services starten: claude-respond.service
... 40x wiederholt ...
[07:12:31] ‚ö†Ô∏è Timeout nach 600s - System nicht ruhig, starte trotzdem
```

### Root Cause
`wait_for_quiet()` erkannte nicht, dass **claude-respond.service die Wartung selbst ist**.

Type=oneshot Services sind im "activating" Status w√§hrend sie laufen. Das ist normal, aber die Wartung sollte sich selbst ignorieren.

### L√∂sung
`wait_for_quiet()` Check 1 filtert jetzt **claude-respond.service** aus:

```bash
# Vorher:
local activating_services=$(systemctl list-units --state=activating ...)

# Nachher:
local activating_services=$(systemctl list-units --state=activating ... | grep -v "^claude-respond.service$")
```

### Ge√§ndert
- `/usr/local/sbin/claude-respond-to-reports`: Zeile 73 - Self-Detection

**Effekt:** Wartung startet sofort, keine 10-Minuten-Wartezeit mehr


## 2026-02-06 - /var/log tmpfs 70% voll: chrony Logging reduziert

### Problem
tmpfs-watchdog warnte alle 5 Minuten:
```
‚ö†Ô∏è Warnung: /var/log bei 70% voll (35MB von 50MB)
```

**Root Cause:** chrony loggte zu verbose
- measurements.log: 1.9MB (13907 Zeilen)
- statistics.log: 2.7MB (23428 Zeilen)
- tracking.log: 1.4MB (10443 Zeilen)
- **Total: 6MB** nur f√ºr chrony (12% von tmpfs!)

### Analyse
chrony Config hatte:
```
log tracking measurements statistics
```

F√ºr GPS/NTP Dauerbetrieb brauchen wir nur **tracking** (wichtigste Daten):
- measurements = Jede einzelne GPS-Messung ‚Üí zu verbose
- statistics = Statistische Auswertungen ‚Üí nur f√ºr Debugging
- tracking = NTP Sync Status ‚Üí das Wichtigste

### L√∂sung
1. **Sofort-Cleanup:**
   - chrony Logs auf 10000 Zeilen gek√ºrzt
   - auth.log auf 5000 Zeilen gek√ºrzt
   - rbfeeder.log, lynis.log, piaware.log gek√ºrzt

2. **Dauerhafte L√∂sung:**
   - chrony Logging auf `log tracking` reduziert
   - measurements.log + statistics.log gel√∂scht
   - chronyd neu gestartet

### Ergebnis
```
Vorher: 50M   35M   16M  70% /var/log
Nachher: 50M   31M   20M  61% /var/log
```

**Effekt:** 
- 9MB Platz gewonnen
- Warnungen stoppen (< 70% Threshold)
- chrony Logs wachsen nur noch 1/3 der vorherigen Rate

### Ge√§ndert
- `/etc/chrony/chrony.conf`: Logging reduziert auf tracking only

**Monitoring:** tmpfs-watchdog pr√ºft weiterhin alle 5min, warnt bei >70%, Emergency-Cleanup bei >90%


## 2026-02-07 - wait_for_quiet: Check 7+8 entfernt (zu aggressiv)

### Problem
Wartung wartete **wieder 10 Minuten** (07:13-07:24):
```
[07:13:53] ‚è≥ Warte auf Ruhe (0s/600s): systemd daemon-reload n√∂tig
... 40x wiederholt ...
[07:24:06] ‚ö†Ô∏è Timeout nach 600s
```

**Root Cause:** Check 7 + Check 8 zu aggressiv

**Check 7:**
```bash
find /etc/systemd/system/ /usr/local/sbin/ -type f -mmin -10
```
Problem: Pr√ºft auch `/usr/local/sbin/` - aber das sind **Skripte**, keine Unit-Files!  
Skript-√Ñnderungen brauchen **kein daemon-reload**.

Gestern: Mehrere Skripte ge√§ndert (wartungs-watchdog, claude-respond-to-reports, chrony.conf)  
‚Üí Check 7 triggerte ‚Üí Check 8 dachte daemon-reload n√∂tig ‚Üí 10min Wartezeit

**Check 8:**
```bash
systemctl status | grep -q "warning.*unit files"
```
Problem: Kann **false positives** geben, reagiert auf systemd Warnungen die nicht relevant sind.

### L√∂sung
**Beide Checks entfernt** (Zeilen 155-164)

`wait_for_quiet()` pr√ºft jetzt nur noch auf **wirklich kritische** Aktivit√§ten:
1. ‚úÖ Services im activating Status (au√üer sich selbst)
2. ‚úÖ Watchdog aktiv (letzte 2min)
3. ‚úÖ Watchdog-Eskalationen
4. ‚úÖ Service-Restarts (letzte 30s)
5. ‚úÖ Andere Claude-Instanz l√§uft
6. ‚úÖ /do Queue Worker l√§uft
7. ‚ùå ~~Service-Configs ge√§ndert~~ (zu aggressiv)
8. ‚ùå ~~systemd daemon-reload n√∂tig~~ (false positives)

### Ge√§ndert
- `/usr/local/sbin/claude-respond-to-reports`: Check 7+8 entfernt

**Effekt:** Wartung startet sofort, keine 10-Minuten-Wartezeiten mehr wegen Skript-√Ñnderungen


## 2026-02-07 - Wartungs-Prompt: Telegram-Redundanz vermeiden

### Problem
Claude sendete **zwei Telegram-Nachrichten**:
1. **07:28** - Lange Nachricht via `telegram-notify` (w√§hrend Wartung)
2. **07:29** - Kurze Nachricht via `[TELEGRAM:OK]` (am Ende)

**Root Cause:** Prompt war unklar
- Erlaubte telegram-notify f√ºr "Nachrichten ohne R√ºckfrage"
- Forderte [TELEGRAM:OK] am Ende
- Claude nutzte BEIDES ‚Üí Redundante Nachrichten

### L√∂sung
Prompt klargestellt (Zeilen 676-680):

**Vorher:**
```
F√ºr Nachrichten ohne R√ºckfrage:
  /usr/local/sbin/telegram-notify "Info-Nachricht"
  /usr/local/sbin/telegram-notify --success "Erfolg"
  /usr/local/sbin/telegram-notify --error "Fehler"
```

**Nachher:**
```
F√ºr Zwischenmeldungen (SELTEN nutzen, nur bei langen Operationen):
  /usr/local/sbin/telegram-notify "Info-Nachricht"  # Nur f√ºr lange Updates

WICHTIG: Nutze telegram-notify nur f√ºr ZWISCHENMELDUNGEN bei langen Operationen!
Die FINALE Wartungszusammenfassung MUSS via [TELEGRAM:OK] am Ende erfolgen.
```

### Ge√§ndert
- `/usr/local/sbin/claude-respond-to-reports`: Prompt-Klarstellung (Zeilen 676-680)

**Effekt:** Claude wird nur noch EINE Telegram-Nachricht senden ([TELEGRAM:OK] am Ende), keine redundanten Zwischenmeldungen mehr
